import streamlit as st
import os
import glob
import pandas as pd
from concurrent.futures import ThreadPoolExecutor, as_completed

# Import Settings
from config.settings import get_project_structure, PROFILES_DIR
from config.selectors import GEMINI_CONFIG
from services.prompt_generator import VisualPromptGenerator

def process_single_file(file_info, assigned_profile_json, gemini_url, chunk_size, dir_output):
    """Worker x·ª≠ l√Ω 1 file SRT -> JSON"""
    input_path = file_info['path']
    file_name = file_info['name']
    
    base_name = os.path.splitext(file_name)[0]
    output_filename = f"{base_name}_prompts.json"
    output_path = os.path.join(dir_output, output_filename)
    
    local_gen = VisualPromptGenerator() 
    
    result_dict = {
        "file": file_name,
        "path": output_path,
        "status": "failed",
        "msg": "Unknown Error",
        "profile": os.path.basename(assigned_profile_json)
    }

    try:
        success = local_gen.generate_via_gemini_web(
            input_srt_path=input_path,
            output_json_path=output_path,
            profile_json_path=assigned_profile_json,
            chunk_size=chunk_size,
            gemini_url=gemini_url
        )
        
        if success:
            result_dict["status"] = "success"
            result_dict["msg"] = "OK"
        else:
            result_dict["msg"] = "Logic returned False"
            
    except Exception as e:
        result_dict["msg"] = str(e)
        
    return result_dict

def render():
    current_proj = st.session_state.get("current_project")
    if not current_proj:
        st.warning("üëà Vui l√≤ng ch·ªçn m·ªôt D·ª± √Ån!")
        return

    paths = get_project_structure(current_proj)
    DIR_INPUT = paths["1_input"]
    DIR_OUTPUT = paths["2_prompts"]

    st.header(f"ü§ñ Step 2: Batch Prompt Generation")

    # =========================================================
    # 1. LOAD FILE SRT (T·ª∞ ƒê·ªòNG + K√âO TH·∫¢)
    # =========================================================
    
    # A. Qu√©t t·ª± ƒë·ªông trong folder
    auto_files = glob.glob(os.path.join(DIR_INPUT, "*.srt"))
    file_options = []
    
    for f in auto_files:
        file_options.append({"name": os.path.basename(f), "path": f, "source": "Auto"})

    # B. K√©o th·∫£ th·ªß c√¥ng (ƒê√£ kh√¥i ph·ª•c l·∫°i cho b·∫°n)
    uploaded_files = st.file_uploader("Ho·∫∑c k√©o th·∫£ file SRT v√†o ƒë√¢y:", type=["srt"], accept_multiple_files=True)
    if uploaded_files:
        for up_file in uploaded_files:
            # L∆∞u file upload v√†o folder input ƒë·ªÉ x·ª≠ l√Ω
            save_path = os.path.join(DIR_INPUT, up_file.name)
            with open(save_path, "wb") as f:
                f.write(up_file.getbuffer())
            
            # Th√™m v√†o danh s√°ch n·∫øu ch∆∞a c√≥
            if save_path not in [x['path'] for x in file_options]:
                file_options.append({"name": up_file.name, "path": save_path, "source": "Upload"})
                st.toast(f"ƒê√£ l∆∞u file: {up_file.name}")

    if not file_options:
        st.info("Ch∆∞a c√≥ file SRT n√†o. H√£y ch·∫°y Step 1 ho·∫∑c k√©o file v√†o tr√™n.")
        return

    # =========================================================
    # 2. CH·ªåN PROFILE & C·∫§U H√åNH
    # =========================================================
    selected_profile_names = st.session_state.get("selected_profiles", [])
    if not selected_profile_names:
        st.error("‚ö†Ô∏è B·∫°n ch∆∞a ch·ªçn Profile n√†o ·ªü thanh b√™n tr√°i (Sidebar)!")
        return

    available_profiles_paths = [os.path.join(PROFILES_DIR, name) for name in selected_profile_names]

    # =========================================================
    # 3. UI DATA EDITOR
    # =========================================================
    data_list = []
    for item in file_options:
        f_name = item["name"]
        expected_json = os.path.join(DIR_OUTPUT, f"{os.path.splitext(f_name)[0]}_prompts.json")
        status_icon = "‚úÖ ƒê√£ xong" if os.path.exists(expected_json) else "‚ö™ Ch∆∞a l√†m"
        
        data_list.append({
            "Ch·∫°y": False, 
            "T√™n File": f_name, 
            "Ngu·ªìn": item["source"],
            "Tr·∫°ng Th√°i": status_icon, 
            "ƒê∆∞·ªùng d·∫´n": item["path"]
        })
    
    df = pd.DataFrame(data_list)
    col1, col2 = st.columns([3, 1])

    with col1:
        st.subheader("üìã Danh s√°ch Input")
        c1, c2 = st.columns(2)
        if c1.button("‚úÖ Ch·ªçn t·∫•t c·∫£"): st.session_state['s2_all'] = True
        if c2.button("‚ùå B·ªè ch·ªçn"): st.session_state['s2_all'] = False
        
        if 's2_all' in st.session_state:
            df["Ch·∫°y"] = st.session_state['s2_all']
            del st.session_state['s2_all']

        edited_df = st.data_editor(
            df, 
            column_config={
                "Ch·∫°y": st.column_config.CheckboxColumn("Ch·ªçn", default=False), 
                "ƒê∆∞·ªùng d·∫´n": None
            }, 
            use_container_width=True, 
            hide_index=True
        )
    
    files_to_process = [{"name": r["T√™n File"], "path": r["ƒê∆∞·ªùng d·∫´n"]} for _, r in edited_df[edited_df["Ch·∫°y"]].iterrows()]

    with col2:
        st.subheader("‚öôÔ∏è C·∫•u h√¨nh")
        
        # üëá [FIX SLIDER CRASH]
        max_limit = len(available_profiles_paths)
        if max_limit > 1:
            max_threads = st.slider("S·ªë lu·ªìng:", 1, max_limit, min(2, max_limit))
        else:
            st.info("‚ÑπÔ∏è ƒêang ch·∫°y 1 Profile")
            max_threads = 1
            
        chunk_size = st.number_input("Chunk Size:", 1, 50, 20)
        st.write("")
        btn_start = st.button(f"üöÄ CH·∫†Y ({len(files_to_process)})", type="primary", disabled=not files_to_process, use_container_width=True)

    # =========================================================
    # 4. TH·ª∞C THI
    # =========================================================
    if btn_start:
        st.divider()
        status_box = st.status(f"‚è≥ ƒêang x·ª≠ l√Ω {len(files_to_process)} files...", expanded=True)
        log = status_box.empty()
        pbar = status_box.progress(0)
        results = []
        
        count = 0
        with ThreadPoolExecutor(max_threads) as executor:
            futures = {}
            for i, f_info in enumerate(files_to_process):
                # Round Robin Profile
                prof = available_profiles_paths[i % len(available_profiles_paths)]
                
                futures[executor.submit(
                    process_single_file, 
                    f_info, prof, 
                    GEMINI_CONFIG["URL"], 
                    chunk_size, DIR_OUTPUT
                )] = f_info["name"]

            for future in as_completed(futures):
                fname = futures[future]
                try:
                    data = future.result()
                    results.append(data)
                    icon = "‚úÖ" if data["status"] == "success" else "‚ùå"
                    log.write(f"{icon} **{fname}** ({data['profile']})")
                except Exception as e:
                    log.write(f"üî• L·ªói {fname}: {e}")
                
                count += 1
                pbar.progress(count / len(files_to_process))

        status_box.update(label="Ho√†n t·∫•t!", state="complete", expanded=False)
        if results:
            st.dataframe(pd.DataFrame(results)[["file", "status", "profile", "msg"]], use_container_width=True)